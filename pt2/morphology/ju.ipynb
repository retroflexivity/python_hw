{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from pymystem3 import Mystem\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "m = Mystem()\n",
        "morph = MorphAnalyzer()\n",
        "with open('book.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "lemmas = m.lemmatize(text)\n",
        "with open('lemmas.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(''.join(lemmas))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "tokens = [w.lower() for w in tokens if w.isalpha()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from json import dumps\n",
        "an_list = []\n",
        "with open('parse.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for word in tokens:\n",
        "        ana = morph.parse(word)[0]\n",
        "        f.write(dumps({'lemma': str(ana.normal_form), 'word': str(ana.word), 'pos': str(ana.tag.POS)}, ensure_ascii=False) + '\\n')\n",
        "        an_list.append((str(ana.normal_form), str(ana.tag.POS)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('russian')\n",
        "\n",
        "pos_freq = {}\n",
        "verbs = {}\n",
        "adverbs = {}\n",
        "for word in an_list:\n",
        "    if word not in sw:\n",
        "        if word[1] != 'None':\n",
        "            pos_freq[word[1]] = pos_freq.get(word[1], 0) + 1\n",
        "        if word[1] in ('VERB', 'INFN', 'PRTF', 'PRTS', 'GRND'):\n",
        "            verbs[word[0]] = verbs.get(word[0], 0) + 1\n",
        "        elif word[1] in ('ADVB', 'PRED'):\n",
        "            adverbs[word[0]] = adverbs.get(word[0], 0) + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "for pos in sorted(pos_freq.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(pos[0], round((pos[1] / len(an_list)), 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(*sorted(verbs, key=verbs.get, reverse=True)[:20], sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "print(*sorted(adverbs, key=adverbs.get, reverse=True)[:20], sep='\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def ngrams(key):\n",
        "    nglist = {}\n",
        "    for ng in key((word[0] for word in an_list)):\n",
        "        nglist[ng] = nglist.get(ng, 0) + 1\n",
        "\n",
        "    return '\\n'.join((' '.join(ng) for ng in sorted(nglist, key=nglist.get, reverse=True)[:25]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from nltk import bigrams\n",
        "print(ngrams(bigrams))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from nltk import trigrams\n",
        "print(ngrams(trigrams))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "paragraph = [word for word in word_tokenize(text.split('\\n')[156])]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "def flip(word):\n",
        "    ana = morph.parse(word)[0]\n",
        "\n",
        "    if ana.tag.POS in ('NOUN', 'ADJF', 'PRTF'):\n",
        "        if ana.tag.number == 'sing' and 'Sgtm' not in ana.tag:\n",
        "            return ana.inflect({'plur'}).word\n",
        "        if ana.tag.number == 'plur' and 'Pltm' not in ana.tag:\n",
        "            return ana.inflect({'sing'}).word\n",
        "\n",
        "    if ana.normal_form in ('он', 'она', 'оно'):\n",
        "        return morph.parse('они')[0].inflect({ana.tag.case}).word\n",
        "\n",
        "    if ana.normal_form == 'они':\n",
        "        return morph.parse('оно')[0].inflect({ana.tag.case}).word\n",
        "\n",
        "    if ana.tag.POS == 'VERB':\n",
        "        if ana.tag.aspect == 'perf':\n",
        "            if ana.tag.tense == 'past':\n",
        "                ana = ana.inflect({'futr', '3per'})\n",
        "            else:\n",
        "                ana = ana.inflect({'past'})\n",
        "        if ana.tag.aspect == 'impf':\n",
        "            if ana.tag.tense == 'past':\n",
        "                ana = ana.inflect({'pres', '3per'})\n",
        "            else:\n",
        "                ana = ana.inflect({'past'})\n",
        "\n",
        "        if ana.tag.number == 'sing':\n",
        "            return ana.inflect({'plur'}).word\n",
        "        else:\n",
        "            return ana.inflect({'sing'}).word\n",
        "\n",
        "    return word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "flipped = ''\n",
        "for word in paragraph:\n",
        "    if word[0].isalpha() or word == '-':\n",
        "        flipped += ' '\n",
        "    flipped += flip(word)\n",
        "\n",
        "flipped[1:]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/usr/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
